### 로지스틱 회귀(Logistic Regression)

확률로 해석이 될수 있는 0~1사이의 값을 출력으로 하는 모델이 필요했는데 그것이 로지스틱 회귀이다. 확률결과에 고정적인 분류 임계값을 적용하면 로지스틱 회귀를 분류기준으로도 활용할 수 있다.



#### 확률계산과 모델학습



##### 로지스틱회귀의 정규화

정규화를 사용하지 않으면 모델이 주어진 데이터 세트에서 손실을 0에 가깝게 만들기 위해 데이터를 더욱 가깝게 맞출 것이다.

 L~2~ 정규화는 가중치가 균형을 잃지 않게 하는데 매우 유용하다.

선형 로지스틱 회귀가 좋은 이유는 무엇?

매우 빠르고 학습 및 예측을 효율적으로 할수 있다는 점.

대량의 데이터에 맞게 확장되는 방법이 필요하거나 지연 시간이 짧은 예측 방법이 필요할 경우 선형 로지스틱 회귀를 사용하는 것이 좋다.

비선형성이 필요한 경우는 특성 교차곱을 추가하면 된다.??

 

### 분류(Classification)

확률결과에 고정적인 분류 **임계값(threshold)**을 적용해 로지스틱 회귀를 분류 기준으로 활용할 수 있다.



그렇다면 이 모델의 품질을 어떻게 평가할까?

대표적인 분류 성능 평가 방법은 **정확성**을 이용하는 것..

기본적으로 옳은 결과의 확률을 말하는 것인데, 아주 직관적이고 널리 사용되는 측정항목이지만 몇 가지 큰 결함이 있다.

클래스 불균형이 존재할 때 오류가 발생한다.

클래스 불균형을 해결하려면 모델이 양성/음성 이나 다른 클래스를 예측하는 방법을 세분화 해야한다.

| True Positivie(TP) | True 인데, True라고 맞춘 경우(맞)   |
| ------------------ | ----------------------------------- |
| False Positive(FP) | False 인데, True라고 한 경우(틀)    |
| True Negative(TN)  | False 인데, False라고 맞춘 경우(맞) |
| False Negative(FN) | True 인데 False 라고 한 경우(틀)    |

> TP, TN은 잘 한 경우, FP, FN은 잘못한 경우. 그런데 FP, FN 중에 뭐가 낫냐고 하면, 그건 Case By Case 다. 예를 들어 암인데, 암이 아니라고 진단하거나, 암이 아닌데 암이 라고 진단하는 케이스는 어떤 경우가 더 나쁠까?



- **정확도(accuracy)** = 전체 케이스중에서 정답을 얼마나 맞췄는가.  

  > TP+TN / TP+TN+FP+FN 

- **정밀도(precision)**  = TP / 분류를 true로 한경우. 

  > TP / TP+FP ( True라고 분류했으면, 진짜 True 일 확률), 양성으로 식별된 사례중 실제로 양성이었던 비율

- **재현율(recall)** = TP / 실제로 true인 경우. 

  > TP / TP+FN (진짜 True 중에 내가 얼마나 True를 정확히 식별했는가에 대한 값), 실제 양성중 정확히 양성이라고 식별된 사례의 비율



cf) Prediction Positive는 분류를 True 라고 말하는 케이스, Condition Positive 는 실제로 True 인 케이스

> Prediction Positive  =  TP + FP
>
>  Condition Positive = TP + FN 



##### **정밀도**(precision) 와 **재현도**(recall)

> 정밀도를 높이고 싶다면 확실할 때만 늑대다!라고 말해야한다. = 분류 임계값을 높이는것

>  재현율을 높이고 싶다면 수풀 속에서 바스락 거리는 소리만 들려도 늑대다! 라고 외쳐야한다. = 분류 임계값을 낮추는것.



정밀도와 재현율 모두 구체적인 분류 임계값을 하나 선택했을 때만 제대로 정의될 수 있다.

하지만, 최고의 분류 임계값을 미리 알 수 없는데 모델의 성능이 어떤지 파악해야 할 때가 있다.

이때는 가능한 여러 분류 임계값에서 모델의 성능을 확인하는 측정항목이 있다. 

이를 ROC 곡선이라 한다.

먼저 모든 분류 임계값을 평가하고 그 임계값을 TP율과 FP율을 확인한다. 이 점들을 연결하는 작은 곡선을 그리면 곡선 아래 영역에 확률적 해석이 도출되는데 이는 AUC(Area Under the roc Curve)라고 한다. 



##### About ROC, AUC Curve

https://www.youtube.com/watch?v=nMAtFhamoRY

https://medium.com/greyatom/lets-learn-about-auc-roc-curve-4a94b4d88152

- **ROC** 곡선(Receiver-Operating Characteristic curve) : 신호를 수신하는 레이더의 특성을 요약해 보여준다는 점에 착안해 명칭을 붙임.

  - 특정 진단 방법의 민감도와 특이도가 어떤 관계를 갖고 있는지를 표현한 그래프.

  - 모든 분류 임계값에서 분류 모델의 성능을 보여주는 그래프

  - **TPR** : True Positive Rate (=**민감도**,**재현율**, true accept rate)

    > 1인 케이스에 대해 1로 예측한 비율(암환자를 진찰해서 암이라고 진단 함)

  - **FPR** :  False Positive Rate (**=특이도**, false accept rate)

    > 0인 케이스에 대해 1로 잘못 예측한 비율(암환자가 아닌데 암이라고 진단 함)

  - TRP과 FPR은 서로 반비례적인 관계에 있기 때문에, 여러가지 상황을 고려해 성능을 판단해서 어떤 지점을 기준으로 잡을지 결정해야하는데 이것을 한눈에 볼 수 있게 한것이 ROC커브. 

    > 예를들어,성급한 의사일경우 아주 조금의 징후만 보여도 암이라고 진단. (TPR=1, FPR=0)
    >
    > 돌팔이 의사일경우 모든 환자에 대해 암이라고 진단. (TPR=0, FPR=1)

  - 어느 쪽에 더 강조를 둘것인가가 중요할 수 있다.

    > 예를들어 걸릴확률은 매우 낮지만 치사율이 극히 높은 병은 민감도가 높아야하고, 걸릴확률은 높지만 위험성이 거의 없는 경우는 민감도가 낮아도 괜찮을것

  - ROC 커브의 면적(AUC)이 1에 가까울수록 좋은 성능이며, 면적은 0.5~1의 범위를 갖는다 (0.5면 성능 전혀 없음, 1이면 최고의 성능)

    

- **AUC**(Area Under the ROC Curve) 

  -  가능한 모든 분류 임계값에서 성능의 집계 측정값을 제공

  - AUC값은 전체적인 민감도와 특이도의 상관 관계를 보여줄 수 있어 매우 편리한 성능 척도에 기준이다.









